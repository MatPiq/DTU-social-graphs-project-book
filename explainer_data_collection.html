
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Data collection &#8212; The Social Science Network</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Descriptive statistics" href="explainer_basicstats.html" />
    <link rel="prev" title="Data collection and descriptive statistics" href="basic_stats_intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">The Social Science Network</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   About this page
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="main.html">
   Main
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="main_data.html">
     Data Description
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="main_results.html">
     Main Results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/MatPiq/social-graphs-embeddings-data/main/document_config.json">
     Document Embeddings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/MatPiq/social-graphs-embeddings-data/main/node_config.json">
     Node Embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="explainer.html">
   Explainer Notebook
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="explainer_motivation.html">
     Motivation
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="basic_stats_intro.html">
     Data collection and descriptive statistics
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Data collection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="explainer_basicstats.html">
       Descriptive statistics
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="explainer_analysis.html">
     Theory, Methods and Analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="explainer_community_detection.html">
       Community detection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="explainer_topic_model.html">
       hSBM topic modelling
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="explainer_embeddings.html">
       Document and Node Embeddings
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="explainer_discussion.html">
     Discussion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="explainer_contributions.html">
     Contributions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/explainer_data_collection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/MatPiq/DTU-social-graphs-project-book/HEAD/v2/gh/MatPiq/DTU-social-graphs-project-book/master?urlpath=lab/tree/explainer_data_collection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/MatPiq/DTU-social-graphs-project-book/blob/master/explainer_data_collection.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Data collection
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-relevant-articles">
     Finding relevant articles
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#collect-page-text-and-edges">
     Collect page text and edges
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#subsetting-a-smaler-network">
     Subsetting a smaler network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#add-preprocessing">
   Add preprocessing
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="data-collection">
<span id="explainer-data-collection"></span><h1>Data collection<a class="headerlink" href="#data-collection" title="Permalink to this headline">¶</a></h1>
<p>This notebook outlines our data collection strategy which consists of the following steps:</p>
<ol class="simple">
<li><p>Finding the relevant Wikipedia pages for each discipline through <a class="reference external" href="https://petscan.wmflabs.org/">PetScan</a>.</p></li>
<li><p>Scraping each page to parse out hyperlinks to other Wikipedia pages and the text.</p></li>
<li><p>Creating a smaller and manageble subgraph from the Network.</p></li>
</ol>
<p>Lastly we will also describe the steps that we have taken to preprocess our data for the purphose of later natural language processing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># imports</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">random</span> 
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">powerlaw</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>

<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">littleballoffur</span>

<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">WordPunctTokenizer</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="finding-relevant-articles">
<h2>Finding relevant articles<a class="headerlink" href="#finding-relevant-articles" title="Permalink to this headline">¶</a></h2>
<p>To collect the relevant wikipedia pages for our project we specify the dataclass <code class="docutils literal notranslate"><span class="pre">WikiPage</span></code>. This is based on the use of the open-source software <a class="reference external" href="https://petscan.wmflabs.org/">PetScan</a> that based on a list of wikipedia-categories yields the corresponding page-names. We furthermore specify the depth of our PetScan-query, which is a measure of how deeply nested we want our categories to be. As the list of pages grows exponentially we limit the levels of depth we set the parameter to 0, 1 and 2. The reason for not choosing one specific depth is that the group and sub-group structure of the disciplines differs which means that we get a widely different amount of pages.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">WikiPage</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data obj that stores an article and </span>
<span class="sd">    its relevant attributes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">title</span><span class="p">:</span><span class="nb">str</span>
    <span class="n">parent</span><span class="p">:</span><span class="nb">str</span>
    <span class="n">depth</span><span class="p">:</span><span class="nb">int</span>
    <span class="n">text</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">edges</span><span class="p">:</span><span class="n">List</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        

<span class="k">def</span> <span class="nf">collect_pages</span><span class="p">(</span><span class="n">parents</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span>
                  <span class="n">depth</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">List</span><span class="p">[</span><span class="n">WikiPage</span><span class="p">]:</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds relevant articles from petscan based on some initial query.</span>
<span class="sd">    See https://petscan.wmflabs.org/ for api reference.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">pages</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1">#setup API call</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://petscan.wmflabs.org/?ns%5B0%5D=1&amp;&#39;</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;project&#39;</span><span class="p">:</span><span class="s1">&#39;wikipedia&#39;</span><span class="p">,</span>
              <span class="s1">&#39;language&#39;</span><span class="p">:</span><span class="s1">&#39;en&#39;</span><span class="p">,</span>
              <span class="s1">&#39;format&#39;</span><span class="p">:</span><span class="s1">&#39;json&#39;</span><span class="p">,</span>
              <span class="s1">&#39;interface_language&#39;</span><span class="p">:</span><span class="s1">&#39;en&#39;</span><span class="p">,</span>
              <span class="s1">&#39;depth&#39;</span><span class="p">:</span><span class="nb">str</span><span class="p">(</span><span class="n">depth</span><span class="p">),</span>
              <span class="s1">&#39;doit&#39;</span><span class="p">:</span><span class="s1">&#39;&#39;</span><span class="p">}</span>
    
    <span class="c1">#Loop over parents and get corresponding page names</span>
    <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">:</span>
        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;categories&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cat</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">base_url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span> 
            <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">resp</span><span class="p">[</span><span class="s1">&#39;*&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;a&#39;</span><span class="p">][</span><span class="s1">&#39;*&#39;</span><span class="p">]:</span>

                <span class="c1">#Append nodes</span>
                <span class="n">pages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">WikiPage</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">page</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span>
                                      <span class="n">parent</span><span class="o">=</span><span class="n">cat</span><span class="p">,</span>
                                      <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">))</span>
                
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">errors</span><span class="o">+=</span><span class="mi">1</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Petscan failed to retrieve </span><span class="si">{</span><span class="n">errors</span><span class="si">}</span><span class="s1"> pages in depth </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="s1">...&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">pages</span>
</pre></div>
</div>
</div>
</div>
<p>Bellow we call the function <code class="docutils literal notranslate"><span class="pre">collect_pages</span></code> and create a page list for depth 0, 1 and 2 and display the resulting counts. As can be seen Anthropology is a clear outlier because of a different group structure on wikipedia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Define initial query groups</span>
<span class="n">query</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;political_science&#39;</span><span class="p">,</span> <span class="s1">&#39;economics&#39;</span><span class="p">,</span> <span class="s1">&#39;sociology&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropology&#39;</span><span class="p">,</span> <span class="s1">&#39;psychology&#39;</span><span class="p">]</span>

<span class="n">depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">pages</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">depths</span><span class="p">):</span>
    <span class="n">pages</span> <span class="o">+=</span> <span class="n">collect_pages</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
    
<span class="c1">#Show marginal distribution of pages</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pages</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;parent&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "d37ac94ffd394c4ea62e83ab5770dfab", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Petscan failed to retrieve 0 pages in depth 0...
Petscan failed to retrieve 0 pages in depth 1...
Petscan failed to retrieve 0 pages in depth 2...
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>parent
anthropology         17621
economics             6023
political_science     7011
psychology            8757
sociology             5895
Name: title, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="collect-page-text-and-edges">
<h2>Collect page text and edges<a class="headerlink" href="#collect-page-text-and-edges" title="Permalink to this headline">¶</a></h2>
<p>In the function <code class="docutils literal notranslate"><span class="pre">collect_attributes</span></code> we use <code class="docutils literal notranslate"><span class="pre">BeautifulSoup</span></code> to scrape the html content from the wikipedia pages we’ve found. The key html node is the <code class="docutils literal notranslate"><span class="pre">div</span></code> with attributes <code class="docutils literal notranslate"><span class="pre">{'id':'mw-content-text'}</span></code> from which we can parse out all paragraphs and hyperlinks, disregarding section headings, tables and other irrelevant content and page attributes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">collect_attributes</span><span class="p">(</span><span class="n">articles</span><span class="p">:</span><span class="nb">list</span><span class="p">[</span><span class="n">WikiPage</span><span class="p">])</span><span class="o">-&gt;</span><span class="nb">list</span><span class="p">[</span><span class="n">WikiPage</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parses the wikipedia article text and urls pointing to another wiki page.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://en.wikipedia.org/wiki/&#39;</span>
    <span class="n">error_log</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">pages</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span> 
                <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">base_url</span><span class="o">+</span><span class="n">page</span><span class="o">.</span><span class="n">title</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">Timeout</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span> 
                <span class="n">error_log</span><span class="p">[</span><span class="n">page</span><span class="o">.</span><span class="n">title</span><span class="p">]</span> <span class="o">=</span> <span class="n">e</span>
            
            <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span><span class="s1">&#39;mw-content-text&#39;</span><span class="p">})</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
            <span class="k">for</span> <span class="n">paragraph</span> <span class="ow">in</span> <span class="n">content</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">):</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">paragraph</span><span class="o">.</span><span class="n">text</span>
            <span class="n">page</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">text</span>
            <span class="n">page</span><span class="o">.</span><span class="n">edges</span> <span class="o">=</span> <span class="p">[</span><span class="n">ref</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">content</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">href</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
                                               <span class="k">if</span> <span class="s1">&#39;wiki&#39;</span> <span class="ow">in</span> <span class="n">ref</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)]</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1">#Log potential errors in collection</span>
            <span class="n">error_log</span><span class="p">[</span><span class="n">page</span><span class="o">.</span><span class="n">title</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">pages</span><span class="p">,</span> <span class="n">error_log</span>

<span class="n">pages</span><span class="p">,</span> <span class="n">error_log</span> <span class="o">=</span> <span class="n">collect_attributes</span><span class="p">(</span><span class="n">pages</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "696250c0808944f5988c82a5f1b5e234", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pages_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pages</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Amount of pages that failed to be collected: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">error_log</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Amount of pages that failed to be collected: 135
</pre></div>
</div>
</div>
</div>
<p>As only 135 out of 45307 pages are missing we do not consider this a problem of substantiel value, why we keep out dataset the way it is.</p>
</div>
<div class="section" id="subsetting-a-smaler-network">
<h2>Subsetting a smaler network<a class="headerlink" href="#subsetting-a-smaler-network" title="Permalink to this headline">¶</a></h2>
<p>Because of the large size of the network, we deem it necessary to create a smaller subgraph that is more manageble. To do this we initially perform three operations:</p>
<ul class="simple">
<li><p>(1) <strong>Restrict anthropology pages to depth = 1</strong>:
Due to the inherent strcuture of Wikipedia we can not expect all of the categories to have an equal amount of pages.
Some categories might be defined more loosely and therefore span broader, whereas other categories might be larger as more people are participates in activities related to the given discpline and therefore more prone to write a Wikipedia page about. No matter the reason, anthropology pages are widely overrepresentative in our dataset, why we decide to restrict the anthropology pages to <code class="docutils literal notranslate"><span class="pre">depth</span> <span class="pre">=</span> <span class="pre">1</span></code>.</p></li>
<li><p>(2) <strong>Remove Duplicates</strong>:
Some pages occur in two categories e.g. the page <em>elitism</em> occur both in political science and anthropology category. As it becomes ambigious to which discipline the page belong we decide to remove them. In cases where some pages occurs several times within the same category (as they are collected at different depths) we collapse them to one observation.</p></li>
<li><p>(3) <strong>Remove edges to pages that did not collect</strong>:
Lastly we remove all edges from the pages we have collected to pages not in our sample.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pages_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;full_data.pickle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">remove_anthro</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove pages in the anthropology category of depth 2</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="o">~</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;depth&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;parent&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;anthropology&quot;</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="k">def</span> <span class="nf">remove_duplicates</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove inter-category page-duplicates and collapse intra-category duplicates</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nodes_to_remove</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">duplicated</span><span class="p">(</span><span class="s2">&quot;title&quot;</span><span class="p">)][</span><span class="s2">&quot;title&quot;</span><span class="p">]))</span> <span class="k">if</span>
                      <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">node</span><span class="p">][</span><span class="s2">&quot;parent&quot;</span><span class="p">]))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">nodes_to_remove</span><span class="p">)]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s2">&quot;title&quot;</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="s2">&quot;first&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
    
<span class="k">def</span> <span class="nf">uniform_page_and_edge_names</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Uniform the spelling and format of string in the title and edges column</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="k">def</span> <span class="nf">remove_edges_not_in_nodelist</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove all edges not in the title column from the lists of edges</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tqdm</span><span class="o">.</span><span class="n">pandas</span><span class="p">()</span>
    <span class="n">nodes</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">progress_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">x</span> <span class="k">if</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># Calling the functions</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">chained_assignment</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Hide Pandas Warnings</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">remove_duplicates</span><span class="p">(</span><span class="n">pages_df</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">remove_anthro</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">uniform_page_and_edge_names</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">remove_edges_not_in_nodelist</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "eb827056769a4e83bb885986a414ef44", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "5f2b1be6ad7649abbd8f03e04bf81b27", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<p>To further subset our data we remove self-loops and model a undirected network from which we extract the giant connected component. We then try to sample a respresntative supgraph containing <span class="math notranslate nohighlight">\(\frac{1}{4}\)</span> of the giant connected component’s nodes using a Metropolis algoritm as stated in <span id="id1">[<a class="reference internal" href="references.html#id17">Hübler <em>et al.</em>, 2008</a>]</span> and implemented in the function <code class="docutils literal notranslate"><span class="pre">.MetropolisHastingsRandomWalkSampler()</span></code> from the module <code class="docutils literal notranslate"><span class="pre">littleballoffur</span></code>. The intuition behind the method is to initialise a random subgraph <span class="math notranslate nohighlight">\(S\)</span> of our full network <span class="math notranslate nohighlight">\(G\)</span> from which we iteratively remove and add nodes in order to mimic some topological properties of <span class="math notranslate nohighlight">\(G\)</span>, in this case the degree-distriubtion. This is of course not without consequences as we remove of the complexity in our network and thereby lose information, however we deem this nesecarry to reduce our network to a more manageble size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We create a dictionary with the index each pagename</span>
<span class="n">index_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">])}</span>

<span class="c1"># We create an edgelist </span>
<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">edges</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
        <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">index_dict</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">index_dict</span><span class="p">[</span><span class="n">edge</span><span class="p">]))</span>
<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">edge_list</span> <span class="k">if</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="c1">#  ... and remove self-loops</span>

<span class="c1"># We model the acutal graph and extract the gcc</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)</span>
<span class="n">gcc</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">connected_components</span><span class="p">(</span><span class="n">G</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">gcc</span><span class="p">)</span>

<span class="c1"># littleballoffur requires all names to be translated into integers</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">relabel</span><span class="o">.</span><span class="n">convert_node_labels_to_integers</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># We make a sample with 0.25 of the gcc&#39;s observations</span>
<span class="n">number_of_nodes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.25</span> <span class="o">*</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">())</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MetropolisHastingsRandomWalkSampler</span><span class="p">(</span><span class="n">number_of_nodes</span> <span class="o">=</span> <span class="n">number_of_nodes</span><span class="p">)</span>
<span class="n">sampled_supgraph</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To asses the bias induced by our sampling we compare the networks in terms of their degree exponent and transitivity. This way we can make sure that the networks degree distribution and level of clusterness is somewhat comparable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="c1"># Calculating the exponent</span>
<span class="n">G_degree_dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">degree</span><span class="p">]</span>
<span class="n">sampled_supgraph_degree_dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sampled_supgraph</span><span class="o">.</span><span class="n">degree</span><span class="p">]</span>
<span class="n">G_exponent</span> <span class="o">=</span> <span class="n">powerlaw</span><span class="o">.</span><span class="n">Fit</span><span class="p">(</span><span class="n">G_degree_dist</span><span class="p">)</span>
<span class="n">sampled_supgraph_exponent</span> <span class="o">=</span> <span class="n">powerlaw</span><span class="o">.</span><span class="n">Fit</span><span class="p">(</span><span class="n">sampled_supgraph_degree_dist</span><span class="p">)</span>

<span class="c1"># Calculating the transitivity</span>
<span class="n">G_transitivity</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">transitivity</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">sampled_supgraph_transitivity</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">transitivity</span><span class="p">(</span><span class="n">sampled_supgraph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Degree distribution exponent full network G: </span><span class="si">{</span><span class="n">G_exponent</span><span class="o">.</span><span class="n">power_law</span><span class="o">.</span><span class="n">alpha</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Degree distribution exponent supgraph S: </span><span class="si">{</span><span class="n">sampled_supgraph_exponent</span><span class="o">.</span><span class="n">power_law</span><span class="o">.</span><span class="n">alpha</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Transitivity full network G: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">transitivity</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Transitivity supgraph S: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">transitivity_sampled</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Degree distribution exponent full network G: 3.2974527129230946
Degree distribution exponent supgraph S: 3.8342121796821265
----------------------------------------------------------------------
Transitivity full network G: 0.1929
Transitivity supgraph S: 0.2991
</pre></div>
</div>
</div>
</div>
<p>Reassuringly, the exponent of the two networks are fairly similiar suggesting that the degree distributions follows the somewhat same structure. A bit more worrying is the difference in transitivity that shows that we have oversestimated the transitivity in our supgraph. The result of this is that our network are more dense with higher number of “triads”, than what really is the case. Nontheless we still decide to use the supgraph for our further analysis. We can now model our final network and corresponding DataFrame that we will use for our analysis based on the nodes from the supgraph. Finally we restrict this network to the weakly connected component as we create a <em>directed</em> network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We define a list of nodes to keep and remove edges that refers to nodes that we have removed</span>
<span class="n">nodes_to_keep</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">index_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">sampled_supgraph</span><span class="o">.</span><span class="n">nodes</span><span class="p">())]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">nodes_to_keep</span><span class="p">)]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()[[</span><span class="s2">&quot;title&quot;</span><span class="p">,</span> <span class="s2">&quot;parent&quot;</span><span class="p">,</span> <span class="s2">&quot;depth&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">]]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">remove_edges_not_in_nodelist</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Set attributes</span>
<span class="n">node_attr</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;title&quot;</span><span class="p">,</span> <span class="s2">&quot;parent&quot;</span><span class="p">,</span> <span class="s2">&quot;depth&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;title&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>

<span class="c1"># Create an edgelist</span>
<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">edges</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
        <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">node</span><span class="p">,</span> <span class="n">edge</span><span class="p">))</span>

<span class="c1"># Model the network</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">set_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node_attr</span><span class="p">)</span>

<span class="c1"># Extract the weakly connected component </span>
<span class="n">gcc</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">weakly_connected_components</span><span class="p">(</span><span class="n">G</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">gcc</span><span class="p">)</span>

<span class="c1"># Add a gcc column to our final DataFrame</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gcc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "5b226fb4ef1744fc9c07fb3752af44cb", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Saving the edgelist as the a directed network can not be pickled</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;Final_edge_list.pickle&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">edge_list</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
<span class="c1"># Saving the node attributes</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;Final_node_attr.pickle&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">node_attr</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="add-preprocessing">
<h1>Add preprocessing<a class="headerlink" href="#add-preprocessing" title="Permalink to this headline">¶</a></h1>
<p>In this section we conduct light preprocessing since the wikipedia documents are fairly clean. We do the following preprocessing steps:</p>
<ul class="simple">
<li><p><strong>1 Getting the clean text from the Wikipedia pages:</strong>
The Wikipedia pages are structued in a page-specific text section and a section with links called “See Also”. We are only intereseted in first one. We clean the text further by removing all non-alphanumerical characters.</p></li>
<li><p><strong>2 Remove stopwords:</strong>
To reduce the size of the pages vocabulary we remove all stopwords as they do not carry a lot of information relative to their size.</p></li>
<li><p><strong>3 Lemmatization of words:</strong>
Lemmatization refer to the reduction of words to its syntactical root to align words despite grammatical modifications which is useful for our analysis of text. We therefore add a column to our final DataFrame with lemmatized words.</p></li>
<li><p><strong>4 Tokenisation of words:</strong>
We split up all the lemmatized pages into list of words (or tokens) and add them to a new column in our final DataFrame.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts clean text from the Wikipedia-pages by splitting</span>
<span class="sd">    non-alphanumerical characters on the &quot;See also&quot; section and removing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;See also&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\W+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">remove_stopwords</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Removes nltk stopwords bounded by whitespace and replace it</span>
<span class="sd">    with whitespace.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">patterns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="n">patterns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">+</span><span class="n">pattern</span><span class="o">+</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>          
            <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">+</span><span class="n">pattern</span><span class="o">+</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">lemmatize</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lemmatize all text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> 
    <span class="n">sent_lemmatized</span> <span class="o">=</span> <span class="p">[</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sent_lemmatized</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize all text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">WordPunctTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="c1"># we apply all functions to the text</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>  <span class="c1"># Ignore DepreciationError</span>
<span class="n">tqdm</span><span class="o">.</span><span class="n">pandas</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">progress_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">clean_text</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;lemmatized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">progress_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">remove_stopwords</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;lemmatized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lemmatized&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">progress_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">lemmatize</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lemmatized&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">.</span><span class="n">progress_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "3d049402f0c64e3cabe5cbc7ad4a239e", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "9f003087d33a4fc794ef030a91b2879a", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "04e50e22b5434f38b8c4c819f77437ba", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "a74d52b4a12a4b55881a3fb8e7dab949", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save final DataFrame</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">&quot;Final_df.pickle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;parent&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>depth</th>
      <th>text</th>
      <th>edges</th>
      <th>gcc</th>
      <th>cleaned_text</th>
      <th>lemmatized</th>
      <th>tokens</th>
    </tr>
    <tr>
      <th>parent</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>anthropology</th>
      <td>510</td>
      <td>510</td>
      <td>510</td>
      <td>510</td>
      <td>510</td>
      <td>510</td>
      <td>510</td>
      <td>510</td>
    </tr>
    <tr>
      <th>economics</th>
      <td>1020</td>
      <td>1020</td>
      <td>1020</td>
      <td>1020</td>
      <td>1020</td>
      <td>1020</td>
      <td>1020</td>
      <td>1020</td>
    </tr>
    <tr>
      <th>political_science</th>
      <td>1614</td>
      <td>1614</td>
      <td>1614</td>
      <td>1614</td>
      <td>1614</td>
      <td>1614</td>
      <td>1614</td>
      <td>1614</td>
    </tr>
    <tr>
      <th>psychology</th>
      <td>543</td>
      <td>543</td>
      <td>543</td>
      <td>543</td>
      <td>543</td>
      <td>543</td>
      <td>543</td>
      <td>543</td>
    </tr>
    <tr>
      <th>sociology</th>
      <td>615</td>
      <td>615</td>
      <td>615</td>
      <td>615</td>
      <td>615</td>
      <td>615</td>
      <td>615</td>
      <td>615</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "MatPiq/DTU-social-graphs-project-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="basic_stats_intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Data collection and descriptive statistics</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="explainer_basicstats.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Descriptive statistics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Frederik Kilpinen, Emilie Munch Gregersen, Matias Piqueras<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>